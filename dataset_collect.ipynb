{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(r\"C:\\prog\\py\\piv\\pivo-segmentation\")\n",
    "\n",
    "DATA_PATH = ROOT_PATH / \"data\"\n",
    "MODEL_PATH = ROOT_PATH / \"models\"\n",
    "\n",
    "logging_format = \"%(name)s - %(asctime)s - %(levelname)s - %(message)s\"\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format=logging_format,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    # filename=ROOT_PATH / \"log.txt\",\n",
    "    # filemode=\"a+\",\n",
    "    encoding=\"utf-8\",\n",
    ")   \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_md5(image_bytes):\n",
    "    \"\"\"\n",
    "    Compute the MD5 hash of the given image bytes.\n",
    "    This simple deduplication method can be replaced by perceptual hashing for fuzzy matching.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(image_bytes).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(img_url, output_dir, dedup_set):\n",
    "    \"\"\"\n",
    "    Downloads an image from the given URL, performs deduplication using MD5 hash,\n",
    "    and saves it with a unique name if it is not a duplicate.\n",
    "\n",
    "    Returns:\n",
    "        file_path (str): Full path to the saved image or None if duplicate/failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(img_url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            image_bytes = response.content\n",
    "            # Compute hash for deduplication\n",
    "            hash_val = compute_md5(image_bytes)\n",
    "            if hash_val in dedup_set:\n",
    "                return None\n",
    "            dedup_set.add(hash_val)\n",
    "            # Create a unique filename using a UUID and the hash value\n",
    "            unique_name = f\"{uuid.uuid4().hex}_{hash_val}.png\"\n",
    "            file_path = os.path.join(output_dir, unique_name)\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            return Path(file_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading image {img_url}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yandex_images_batch_generator(prompt, output_dir, batch_size=10):\n",
    "    \"\"\"\n",
    "    Generator that queries Yandex Images for a fixed search query, downloads images in batches of `batch_size`,\n",
    "    and yields a list of file paths to the downloaded images.\n",
    "    \n",
    "    Deduplication is performed by computing the MD5 hash of the image bytes.\n",
    "    A more robust method might use perceptual hashing (e.g., using the imagehash library).\n",
    "    \n",
    "    Parameters:\n",
    "        output_dir (str): Directory where images will be saved.\n",
    "        batch_size (int): Number of images per batch.\n",
    "    \n",
    "    Yields:\n",
    "        batch (list): List of file paths for the downloaded images in the batch.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dedup_set = set()\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    url = f\"https://yandex.ru/images/search?text={prompt}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for the page to load\n",
    "    \n",
    "    batch = []\n",
    "    idx = 0\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, \"img\")\n",
    "    \n",
    "    while True:\n",
    "        # Scroll if necessary to load more images\n",
    "        if idx >= len(images):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            images = driver.find_elements(By.CSS_SELECTOR, \"img\")\n",
    "            if idx >= len(images):\n",
    "                break  # No more images to process\n",
    "        \n",
    "        try:\n",
    "            image_element = images[idx]\n",
    "            # Get image URL. Sometimes the real URL is in the 'src' attribute, sometimes in 'data-src'\n",
    "            img_url = image_element.get_attribute(\"src\")\n",
    "            if not img_url or img_url.startswith(\"data:\"):\n",
    "                idx += 1\n",
    "                continue\n",
    "            file_path = download_image(img_url, output_dir, dedup_set)\n",
    "            if file_path:\n",
    "                batch.append(file_path)\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []  # Reset batch after yielding\n",
    "            idx += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing image index {idx}: {e}\")\n",
    "            idx += 1\n",
    "\n",
    "    # Yield any remaining images\n",
    "    if batch:\n",
    "        yield batch\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = SAM2AutomaticMaskGenerator.from_pretrained(\n",
    "    model_id=\"facebook/sam2.1-hiera-large\",\n",
    "    points_per_side=64,\n",
    "    points_per_batch=128,\n",
    "    pred_iou_thresh=0.85,\n",
    "    stability_score_thresh=0.92,\n",
    "    stability_score_offset=0.7,\n",
    "    crop_n_layers=1,\n",
    "    box_nms_thresh=0.5,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=25.0,\n",
    "    use_m2m=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_ratio(bbox):\n",
    "    _, _, w, h = bbox\n",
    "    return h / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_constrain(bboxes, constrain=(1.5, 5), metric=bbox_ratio):\n",
    "    scalars = np.array([metric(i) for i in bboxes])\n",
    "    mask1 = scalars < constrain[1]\n",
    "    mask2 = scalars > constrain[0]\n",
    "    return np.array(bboxes)[mask1 & mask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppress_inside_bboxes(bboxes, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Suppresses bounding boxes that are mostly inside larger ones.\n",
    "    \n",
    "    Args:\n",
    "        bboxes (list or np.ndarray): List of bboxes in [x, y, w, h] format.\n",
    "        threshold (float): Fraction of smaller box area that must be inside the larger one to suppress.\n",
    "        \n",
    "    Returns:\n",
    "        list: Filtered list of bboxes.\n",
    "    \"\"\"\n",
    "    def bbox_area(b):\n",
    "        return b[2] * b[3]\n",
    "\n",
    "    def intersection_area(b1, b2):\n",
    "        x1, y1 = max(b1[0], b2[0]), max(b1[1], b2[1])\n",
    "        x2 = min(b1[0] + b1[2], b2[0] + b2[2])\n",
    "        y2 = min(b1[1] + b1[3], b2[1] + b2[3])\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0\n",
    "        return (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    bboxes = np.array(list(bboxes))\n",
    "    keep = [True] * len(bboxes)\n",
    "\n",
    "    for i in range(len(bboxes)):\n",
    "        for j in range(len(bboxes)):\n",
    "            if i == j or not keep[i] or not keep[j]:\n",
    "                continue\n",
    "\n",
    "            area_i = bbox_area(bboxes[i])\n",
    "            area_j = bbox_area(bboxes[j])\n",
    "            inter = intersection_area(bboxes[i], bboxes[j])\n",
    "\n",
    "            if area_i < area_j:\n",
    "                if inter / area_i >= threshold:\n",
    "                    keep[i] = False\n",
    "            elif area_j < area_i:\n",
    "                if inter / area_j >= threshold:\n",
    "                    keep[j] = False\n",
    "\n",
    "    return bboxes[keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_bboxes(image_path, mask_generator):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        raw_mask = mask_generator.generate(image)\n",
    "        bbox = np.array([i[\"bbox\"] for i in raw_mask])\n",
    "        bbox = filter_by_constrain(bbox)\n",
    "        bbox = suppress_inside_bboxes(bbox)\n",
    "        \n",
    "        return image, bbox\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in get_image_and_bboxes - {e}\")\n",
    "        return None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_bboxes(image: np.array, bboxes: list, bbox_dir: str, csv_dir: str, image_path: str):\n",
    "    \"\"\"\n",
    "    Extracts bounding boxes from an image, saves each cropped region as a PNG with a filename\n",
    "    based on the parent image name, and creates a CSV file listing each bounding box's details.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.array): Input image in numpy array format.\n",
    "        bboxes (list): List of bounding boxes in (x, y, w, h) format.\n",
    "        output_dir (str): Directory where the cropped images will be saved.\n",
    "        csv_path (str): Directory where the CSV file will be saved.\n",
    "        image_path (str): Path to the parent image file (used to derive the image name).\n",
    "    \n",
    "    CSV File:\n",
    "        The CSV file will have the following columns:\n",
    "        X, Y, W, H, FileName\n",
    "        \n",
    "        It will be saved with the same base name as the parent image, with '.csv' appended.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(bbox_dir, exist_ok=True)\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    \n",
    "    csv_rows = []\n",
    "    \n",
    "    for idx, (x, y, w, h) in enumerate(bboxes.astype(int)):\n",
    "        cropped = image[y:y+h, x:x+w]\n",
    "        file_name = f\"{base_name}_{idx}.png\"\n",
    "        file_path = os.path.join(bbox_dir, file_name)\n",
    "        cv2.imwrite(file_path, cropped)\n",
    "        csv_rows.append([x, y, w, h, file_name])\n",
    "    \n",
    "    csv_file_name = f\"{base_name}.csv\"\n",
    "    csv_file_path = os.path.join(csv_dir, csv_file_name)\n",
    "    \n",
    "    with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"X\", \"Y\", \"W\", \"H\", \"FileName\"])\n",
    "        writer.writerows(csv_rows)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline(image_path, mask_generator, bboxes_dir, csv_dir):\n",
    "    image, bbox = get_image_and_bboxes(image_path, mask_generator)\n",
    "    if image is None or len(bbox) == 0:\n",
    "        return False\n",
    "    extract_and_save_bboxes(image, bbox, bboxes_dir, csv_dir, image_path)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = Path(r\"C:\\prog\\py\\piv\\dataset_raw\\my_group\")\n",
    "bboxes_dir = Path(r\"C:\\prog\\py\\piv\\dataset_raw\\bboxes\")\n",
    "csv_dir = Path(r\"C:\\prog\\py\\piv\\dataset_raw\\csv\")\n",
    "\n",
    "os.makedirs(bboxes_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__ - 19:15:45 - WARNING - Start\n",
      "  0%|          | 0/432 [00:00<?, ?it/s]C:\\prog\\repos\\sam2\\sam2\\sam2_image_predictor.py:431: UserWarning: cannot import name '_C' from 'sam2' (C:\\prog\\repos\\sam2\\sam2\\__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
      "  masks = self._transforms.postprocess_masks(\n",
      "100%|██████████| 432/432 [3:07:25<00:00, 26.03s/it]  \n",
      "__main__ - 22:23:11 - WARNING - End\n"
     ]
    }
   ],
   "source": [
    "logger.warning(\"Start\")\n",
    "image_paths = list(images_dir.iterdir())\n",
    "for path in tqdm(image_paths):\n",
    "    try:\n",
    "        status = image_pipeline(path, mask_generator, bboxes_dir, csv_dir)\n",
    "        if not status:\n",
    "            logger.error \n",
    "    except Exception as e:\n",
    "        logger.error(f\"path:{path}, exception:{e}\")\n",
    "\n",
    "logger.warning(\"End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"полка с пивом в магазине\",\n",
    "    \"полка с алкоголем в магазине\",\n",
    "    \"полка с напитками в магазине\",\n",
    "]\n",
    "\n",
    "num_images_per_prompt = [\n",
    "    500,\n",
    "    300,\n",
    "    200,\n",
    "]\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "downloaded_dir = DATA_PATH / \"downloaded\"\n",
    "bboxes_dir = DATA_PATH / \"bboxes\"\n",
    "csv_dir = DATA_PATH / \"csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "полка с пивом в магазине:   0%|                                                                | 0/500 [00:00<?, ?it/s]C:\\prog\\repos\\sam2\\sam2\\sam2_image_predictor.py:431: UserWarning: cannot import name '_C' from 'sam2' (C:\\prog\\repos\\sam2\\sam2\\__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
      "  masks = self._transforms.postprocess_masks(\n"
     ]
    }
   ],
   "source": [
    "already_downloaded = len(list(downloaded_dir.iterdir())) if downloaded_dir.exists() else 0\n",
    "logger.warning(\"Start\")\n",
    "\n",
    "for prompt, num_images in zip(prompts, num_images_per_prompt):\n",
    "    generator = yandex_images_batch_generator(prompt, downloaded_dir, batch_size=batch_size)\n",
    "\n",
    "    with tqdm(total=num_images, desc=prompt) as bar:\n",
    "        bar.update(already_downloaded)\n",
    "        while True:\n",
    "            try:\n",
    "                batch = next(generator)\n",
    "                counter = 0\n",
    "                for path in batch:\n",
    "                    status = image_pipeline(path, mask_generator, bboxes_dir, csv_dir)\n",
    "                    if status:\n",
    "                        counter += 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            os.remove(path)\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                bar.update(counter)\n",
    "                already_downloaded += len(batch)\n",
    "\n",
    "                if already_downloaded >= num_images:\n",
    "                    break\n",
    "            except StopIteration:\n",
    "                break\n",
    "logger.warning(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.png': 605})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.suffix for i in downloaded_dir.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faulted = []\n",
    "for image_path in downloaded_dir.iterdir():\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        pd.read_csv(image_path.parent.parent / \"csv\"/ (image_path.stem + \".csv\"))\n",
    "    except:\n",
    "        faulted.append(image_path)\n",
    "len(faulted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_bboxes = pd.DataFrame([len(pd.read_csv(i)) for i in csv_dir.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PlotAccessor.hexbin() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnum_of_bboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhexbin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: PlotAccessor.hexbin() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "num_of_bboxes.plot.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in faulted:\n",
    "    # os.remove(i)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6, 582)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(downloaded_dir.iterdir())), len(list(csv_dir.iterdir())), len(list(bboxes_dir.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"awkward\n",
    "clumsy\n",
    "complex\n",
    "frustrating\n",
    "time\n",
    "-consuming\n",
    "tricky\n",
    "accept\n",
    "adapt\n",
    "be a step forward\n",
    "be capable of\n",
    "be frightened of\n",
    "can’t take\n",
    "cope with\n",
    "get a grip\n",
    "resist\n",
    "survive\n",
    "tackle\n",
    "underestimate\n",
    "be a waste of time\n",
    "be hard to operate\n",
    "drive crazy\n",
    "lose patience\n",
    "get on nerves\n",
    "amateur\n",
    "binge\n",
    "-watch\n",
    "DIY (do-it-yourself)\n",
    "revive\n",
    "preserve\n",
    "adaptable\n",
    "endangered\n",
    "poisonous\n",
    "atmosphere\n",
    "exploration\n",
    "investigation\n",
    "satellite\n",
    "species\n",
    "surface\n",
    "resources\n",
    "creature\n",
    "habitat\n",
    "survivor\n",
    "pond\n",
    "observe\n",
    "volcano\n",
    "launch\n",
    "to monitor\n",
    "preserve\n",
    "use up\n",
    "fossil\n",
    "head straight for\n",
    "microbe\n",
    "mammal\n",
    "bizarre\n",
    "creepy\n",
    "disgusting\n",
    "fabulous\n",
    "impressive\n",
    "irritating\n",
    "satisfying\n",
    "stunning\n",
    "tense\n",
    "uneasy\n",
    "weird\n",
    "to attract attention\n",
    "to be extrovert\n",
    "to be introvert\n",
    "to be reserved\n",
    "to be the life of the party\n",
    "to feel left out\n",
    "to interact with people\n",
    "socialize\n",
    "speak softly\n",
    "to show off\n",
    "to speak up\n",
    "That’s gross!\n",
    "cookware\n",
    "database\n",
    "intern\n",
    "personal statement\n",
    "stereotype\n",
    "constructive\n",
    "destructive\n",
    "unreasonable\n",
    "valid\n",
    "aspect\n",
    "weakness\n",
    "assist\n",
    "build trust\n",
    "oversee\n",
    "steer sb away from\n",
    "assess\n",
    "draw attention to\n",
    "point out\n",
    "think through\n",
    "weigh the pros and cons\n",
    "be (get) stuck with\n",
    "anxiety level\n",
    "breathing technique\n",
    "be conscious of\n",
    "be in control of\n",
    "be rational\n",
    "be scared to death\n",
    "cure an illness\n",
    "overcome my fear\n",
    "panic about sth\n",
    "regain control\n",
    "try a therapy\n",
    "be dying to\n",
    "be eager to\n",
    "be more than happy to\n",
    "be passionate about\n",
    "be prepared to\n",
    "be reluctant to\n",
    "be unwilling to\n",
    "have no desire to\n",
    "hesitate to\n",
    "barrier\n",
    "face time\n",
    "gesture\n",
    "isolation\n",
    "millennial\n",
    "catch sb’s attention\n",
    "get hits\n",
    "get publicity\n",
    "have a good reputation\n",
    "make an appearance\n",
    "make headlines\n",
    "praise sb\n",
    "raise awareness\n",
    "seek fame\n",
    "announce\n",
    "boast\n",
    "confirm\n",
    "deny\n",
    "estimate\n",
    "insist\n",
    "propose\n",
    "swear\n",
    "Then it hit me.\n",
    "trade\"\"\".replace(\"\\n-\", \"-\").split(\"\\n\")\n",
    "b = []\n",
    "for i in range(0, len(a), len(a) // 4):\n",
    "    b.append(a[i:i+len(a)//4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(*b[4],sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
